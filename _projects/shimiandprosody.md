---
redirect_from: "/emotionalmusicalprosody"
title: 'Emotional Musical Prosody'
subtitle: 'Using Musical Prosody for Robotic Interaction'
date: 2020-02-30 00:00:00
description: This page is a demo that shows everything you can do inside portfolio and blog posts.
featured_image: '/images/shimi.jpg'
---
<iframe width="560" height="315" src="https://www.youtube.com/embed/mDAmApNw5wo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

###### About:
My work with Emotional Musical Prosody started with the broad question of what voice a robot should use to communicate. I focused on generating a new non-speech voice, aiming to avoid uncanny valley, and allow a robot to talk like a robot. This was done using prosodic audio generated through deep learning on an embedded Nvidia Jetson TX2. After creating the voice I was able to show increased levels of trust in users when collaborating with Shimi. These metrics then led to the development of a successful NSF grant with my advisor Gil Weinberg, which commenced in November 2019.

After being awarded the NSF grant, the main portion of my PhD reserach focused on expanding Emotional Musical Prosody to robotic arms and groups of robots, eventually becoming my dissertation: [Machine Learning Driven Emotional Musical Prosody for Human-Robot Interaction](https://smartech.gatech.edu/handle/1853/66096)



### Grants
###### National Science Foundation, National Robotics Initiative - $803,892.00
In 2019 I was the primary author with my advisor Gil Weinberg for an NSF grant [Creating Trust Between Groups of Humans and Robots Using a Novel Music Driven Robotic Emotion Generator](https://www.nsf.gov/awardsearch/showAward?AWD_ID=1925178&HistoricalAwards=false)

### Press:
[Shimi Will Now Sing to You in an Adorable Robot Voice](https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/shimi-will-now-sing-to-you-in-an-adorable-robot-voice)
IEEE Spectrum - 05 Mar 2019


### Publications:
[Machine Learning Driven Emotional Musical Prosody for Human-Robot Interaction](https://smartech.gatech.edu/handle/1853/66096)

Georgia Tech, PhD Dissertation

Committee:
- Dr Gil Weinberg (Advisor)
- Dr Claire Arthur
- Dr Jason Freeman
- Dr Ayanna Howard


<!-- *Abstract:*
This dissertation presents a method for non-anthropomorphic human-robot interaction using a newly developed concept entitled Emotional Musical Prosody (EMP). EMP consists of short expressive musical phrases capable of conveying emotions, which can be embedded in robots to accompany mechanical gestures. The main objective of EMP is to improve human engagement with, and trust in robots while avoiding the uncanny valley. We contend that music - one of the most emotionally meaningful human experiences - can serve as an effective medium to support human-robot engagement and trust. EMP allows for the development of personable, emotion-driven agents, capable of giving subtle cues to collaborators while presenting a sense of autonomy. We present four research areas aimed at developing and understanding the potential role of EMP in human-robot interaction. The first research area focuses on collecting and labeling a new EMP dataset from vocalists, and using this dataset to generate prosodic emotional phrases through deep learning methods. Through extensive listening tests, the collected dataset and generated phrases were validated with a high level of accuracy by a large subject pool. The second research effort focuses on understanding the effect of EMP in human-robot interaction with industrial and humanoid robots. Here, significant results were found for improved trust, perceived intelligence, and likeability of EMP enabled robotic arms, but not for humanoid robots. We also found significant results for improved trust in a social robot, as well as perceived intelligence, creativity and likeability in a robotic musician. The third and fourth research areas shift to broader use cases and potential methods to use EMP in HRI. The third research area explores the effect of robotic EMP on different personality types focusing on extraversion and neuroticism. For robots, personality traits offer a unique way to implement custom responses, individualized to human collaborators. We discovered that humans prefer robots with emotional responses based on high extraversion and low neuroticism, with some correlation between the humans collaboratorâ€™s own personality traits. The fourth and final research question focused on scaling up EMP to support interaction between groups of robots and humans. Here, we found that improvements in trust and likeability carried across from single robots to groups of industrial arms. Overall, the thesis suggests EMP is useful for improving trust and likeability for industrial, social and robot musicians but not in humanoid robots. The thesis bears future implications for HRI designers, showing the extensive potential of careful audio design, and the wide range of outcomes audio can have on HRI. -->


[Emotional musical prosody for the enhancement of trust: Audio design for robotic arm communication](https://www.degruyter.com/document/doi/10.1515/pjbr-2021-0033/html)

Richard Savery, Lisa Zahray, Gil Weinberg

Paladyn, Journal of Behavioral Robotics

[Before, Between, and After: Enriching Robot Communication Surrounding Collaborative Creative Activities](https://www.frontiersin.org/articles/10.3389/frobt.2021.662355/abstract)

Richard Savery, Lisa Zahray, Gil Weinberg

Frontiers in Robotics and AI: Creativity and Robotics, 2021

[Machine Learning Driven Musical Improvisation for Mechanomorphic Human-Robot Interaction](https://dl.acm.org/doi/10.1145/3434074.3446351)

Richard Savery

ACM/IEEE International Conference on Human-Robot Interaction, 2021


[Emotion Musical Prosody for Robotic Groups and Entitativity](https://ieeexplore.ieee.org/document/9515314)

Richard Savery, Amit Rogel and Gil Weinberg,

30th IEEE International Conference on Robot & Human Interactive Communication, 2021

[Musical Prosody-Driven Emotion Classification: Interpreting Vocalists Portrayal of Emotions Through Machine Learning](https://arxiv.org/abs/2106.02556)

Nic Farris, Brian Model, Richard Savery, Gil Weinberg,

18th Sound and Music Computing Conference, 2021

[Emotional  Musical  Prosody  for  the  Enhancement  of  Trust  in  Robotic Arm  Communication](https://arxiv.org/pdf/2009.09048.pdf)

Richard Savery, Lisa Zahray, Gil Weinberg

Trust, Acceptance and Social Cues in Human-Robot Interaction, Ro-MAN 2020

[Emotional Musical Prosody: Validated Vocal Dataset for Human Robot Interaction](https://arxiv.org/pdf/2010.04839.pdf)

Richard Savery, Lisa Zahray, Gil Weinberg

2020 Joint Conference on AI Music Creativity


[Establishing  Human-Robot  Trust  through  Music-Driven  Robotic Emotion  Prosody  and  Gesture](https://arxiv.org/pdf/2001.05863.pdf)

28th IEEE International Conference on Robot & Human Interactive Communication 2019

Richard Savery, Ryan Rose and Gil Weinberg

[Finding Shimi's Voice: Fostering Human-Robot Communication With Music And a NVIDIA Jetson TX2](http://lac.linuxaudio.org/2019/doc/savery.pdf)

Linux Audio Conference 2019

R Savery, R Rose, G Weinberg
