---
title: 'FOREST'
subtitle: 'Interactive Robotic Arms'
date: 2019-06-30 00:00:00
description: Musical Forest
featured_image: '/images/forest.jpeg'
---
###### About:
During my research in [Emotional Musical Prosody](https://richardsavery.com/project/shimiandprosody), we consistently found that embedding emotion-driven sounds and gestures in robotic arms help establish trust and likability between humans and their AI counterparts. To expand this work into public performance, I helped develop and program the interactive performance â€œFOREST", consisting of improvising robot musicians, and dancers who interact with human partners. Much of my research is present throughout the performance, including deep learning generated audio, all lyrics through deep learning, and other musical ideas.


### Video

<iframe width="560" height="315" src="https://www.youtube.com/embed/J2Ekt_SI8Qg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<iframe width="560" height="315" src="https://www.youtube.com/embed/YIX6ImUzdqs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Selected Press and Videos

[Finding Their Groove](https://research.gatech.edu/finding-their-groove)

[Building Human-Robot Relationships Through Music and Dance: A performance called FOREST is exploring trust through creative collaboration](https://spectrum.ieee.org/robot-dance-music) IEEE Spectrum, 1st December 2021
